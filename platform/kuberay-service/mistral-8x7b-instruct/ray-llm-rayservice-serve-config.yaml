apiVersion: ray.io/v1
kind: RayService
metadata:
  name: rayllm
spec:
  serviceUnhealthySecondThreshold: 1200 # Config for the health check threshold for service. Default value is 60.
  deploymentUnhealthySecondThreshold: 1200 # Config for the health check threshold for deployments. Default value is 60.
  serveConfigV2: |
    applications:
    - name: ray-llm
      route_prefix: /
      import_path: rayllm.backend:router_application
      args:
        models:
        - "./models/mistral--mixtral-8x7b-instruct.yaml"
  rayClusterConfig:
    # Ray head pod template
    headGroupSpec:
      # The `rayStartParams` are used to configure the `ray start` command.
      # See https://github.com/ray-project/kuberay/blob/master/docs/guidance/rayStartParams.md for the default settings of `rayStartParams` in KubeRay.
      # See https://docs.ray.io/en/latest/cluster/cli.html#ray-start for all available options in `rayStartParams`.
      rayStartParams:
        # Setting "num-cpus: 0" to avoid any Ray actors or tasks being scheduled on the Ray head Pod.
        num-cpus: "0"
        dashboard-host: '0.0.0.0'
        block: 'true'
        disable-usage-stats: 'true'
      #pod template
      template:
        spec:
          imagePullSecrets:
          - name: docker-hub-regcred
          containers:
          - name: ray-head
            image: anyscale/ray-llm:latest
            resources:
              limits:
                cpu: "8"
                memory: "200Gi"
              requests:
                cpu: "2"
                memory: "8Gi"
            volumeMounts:
            - mountPath: /home/ray/models
              name: model
            ports:
            - containerPort: 6379
              name: gcs-server
            - containerPort: 8265 # Ray dashboard
              name: dashboard
            - containerPort: 10001
              name: client
            - containerPort: 8000
              name: serve
          volumes:
          - name: model
            configMap:
              name: mixtral-8x7b-instruct
              items:
              - key: mistral--mixtral-8x7b-instruct.yaml
                path: mistral--mixtral-8x7b-instruct.yaml
    workerGroupSpecs:
    # the pod replicas in this group typed worker
    - replicas: 4
      minReplicas: 1
      maxReplicas: 4
      # logical group name, for this called small-group, also can be functional
      groupName: gpu-group
      rayStartParams:
        block: 'true'
        resources: '"{\"accelerator_type:L40S\": 1}"'
        disable-usage-stats: 'true'
      # pod template
      template:
        spec:
          imagePullSecrets:
          - name: docker-hub-regcred
          securityContext:
            runAsUser: 1000
            fsGroup: 100
          containers:
          - name: llm
            image: anyscale/ray-llm:latest
            lifecycle:
              preStop:
                exec:
                  command: ["/bin/sh", "-c", "ray stop"]
            resources:
              limits:
                cpu: "8"
                memory: "200Gi"
                ephemeral-storage: "150Gi"
                nvidia.com/gpu: "1"
              requests:
                cpu: "2"
                memory: "20Gi"
                ephemeral-storage: "150Gi"
                nvidia.com/gpu: "1"
          # Please ensure the following taint has been applied to the GPU node in the cluster.
          tolerations:
          - key: "ray.io/node-type"
            operator: "Equal"
            value: "worker"
            effect: "NoSchedule"
            #nodeSelector:
            #  cloud.google.com/gke-accelerator: nvidia-l4
